{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saif-Saket/100-pandas-puzzles/blob/master/_downloads/3dbbd6931d76adb0dc37d4e88b328852/tensor_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fGyN-R2--mmo"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://docs.pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19unlW8I-mmp"
      },
      "source": [
        "Tensors\n",
        "=======\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays\n",
        "and matrices. In PyTorch, we use tensors to encode the inputs and\n",
        "outputs of a model, as well as the model's parameters.\n",
        "\n",
        "Tensors are similar to NumPy's ndarrays, except that tensors can run on\n",
        "GPUs or other specialized hardware to accelerate computing. If you're\n",
        "familiar with ndarrays, you'll be right at home with the Tensor API. If\n",
        "not, follow along in this quick API walkthrough.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E3fM5Uc9-mmp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rftpHqp-mmp"
      },
      "source": [
        "Tensor Initialization\n",
        "=====================\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following\n",
        "examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is\n",
        "automatically inferred.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ACNUtU6h-mmq"
      },
      "outputs": [],
      "source": [
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDB299en-mmq"
      },
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa - see\n",
        "`bridge-to-np-label`{.interpreted-text role=\"ref\"}).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2ec2phdG-mmq"
      },
      "outputs": [],
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZyZZjbP-mmq"
      },
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument\n",
        "tensor, unless explicitly overridden.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_BsNkUo5-mmq",
        "outputId": "d9f37f37-5a28-479c-c6ac-dcc5ca561dff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.1710, 0.7520],\n",
            "        [0.9469, 0.2179]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZlW68zG-mmq"
      },
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "`shape` is a tuple of tensor dimensions. In the functions below, it\n",
        "determines the dimensionality of the output tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6C7-ekdS-mmq",
        "outputId": "62e82246-d6c2-454c-e5a2-7b7e3238f073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.1475, 0.2342, 0.7585],\n",
            "        [0.5103, 0.1463, 0.2656]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "shape = (2, 3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYii3HA9-mmq"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8DM6c-a-mmq"
      },
      "source": [
        "Tensor Attributes\n",
        "=================\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on\n",
        "which they are stored.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LgXLK3fm-mmq",
        "outputId": "f4e74a18-7052-4c18-a9ba-c31e61546b21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the tensor: \n",
            "tensor([[0.5198, 0.1791, 0.1042, 0.6124],\n",
            "        [0.3983, 0.9729, 0.9895, 0.8263],\n",
            "        [0.2390, 0.4012, 0.3419, 0.7188]])\n",
            "\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "ndim of tensor: 2\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n",
            "<class 'torch.Size'>\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "# the attributes of the tesors are (shape, ndim, dtype, device):\n",
        "  - ndim: the num of dimention of the tensor (0 \"Scalar\", 1 \"vector\", 2 \"Matrix\", 3 \"tensor\")\n",
        "  - shape: we explained it before, it return value like: torch.Size([3, 4]) which is a <class 'torch.Size'>.\n",
        "    # we can access it by index [0] => first value [1]...\n",
        "  - dtype: return the datatype of the tensor (which is a tensor data) ex: torch.float32 (tensor with float32 data).\n",
        "  - device: the device of that the tensor are stored in (CPU, GPU, TPU).\n",
        "\"\"\"\n",
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f\"the tensor: \\n{tensor}\\n\")\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"ndim of tensor: {tensor.ndim}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "print(type(tensor.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6NfISSK-mmr"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioubmPfG-mmr"
      },
      "source": [
        "Tensor Operations\n",
        "=================\n",
        "\n",
        "Over 100 tensor operations, including transposing, indexing, slicing,\n",
        "mathematical operations, linear algebra, random sampling, and more are\n",
        "comprehensively described\n",
        "[here](https://pytorch.org/docs/stable/torch.html).\n",
        "\n",
        "Each of them can be run on the GPU (at typically higher speeds than on a\n",
        "CPU). If you're using Colab, allocate a GPU by going to Edit \\> Notebook\n",
        "Settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bSXMDaLk-mmr",
        "outputId": "ab17b1f5-334e-4fdd-de18-b33d38282ed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "# we need to move the tensor to GPU to apply Operations faster.\n",
        "# first by the \"torch.cuda\" class we use the \".is_available()\" method to check if the cuda are available.\n",
        "# if it is available we move the tensor by the \"tensor_var.to()\" and spesify the 'cuda' => tensor.to('cuda').\n",
        "# we then check the device attribute for that tensor\n",
        "\"\"\"\n",
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kULDomVq-mmr"
      },
      "source": [
        "Try out some of the operations from the list. If you\\'re familiar with\n",
        "the NumPy API, you\\'ll find the Tensor API a breeze to use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwJNdk6A-mmr"
      },
      "source": [
        "**Standard numpy-like indexing and slicing:**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "tensor"
      ],
      "metadata": {
        "id": "ulwzDP3FJFRO",
        "outputId": "e66c90c8-bae0-47cd-ee16-2e23968c2739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AbHk7diX-mmr",
        "outputId": "ca48f78d-8fa8-407e-ca47-b261a9e93309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWTCGIS9-mmr"
      },
      "source": [
        "**Joining tensors** You can use `torch.cat` to concatenate a sequence of\n",
        "tensors along a given dimension. See also\n",
        "[torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html),\n",
        "another tensor joining op that is subtly different from `torch.cat`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XmGFU2Q6-mmr",
        "outputId": "df2645b9-d757-428c-fe84-1c551451f1d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors datatypes**"
      ],
      "metadata": {
        "id": "rho4wFq9WXdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# by default when we create a tenosr by (torch.tensor, .rand, .zeros, .ones, .rand_like...) the tensor Datatype is the \"torch.float32\" but we can change it.\n",
        "# the tensors Datatype is very importent because it takes spaces in the memory and any Operation is faster on the small datatypes ex: float16 (faster than) float32,\n",
        "  and it's one of the 3 big errors to manipulate in the Pytorch:\n",
        "  1. Tensors not right datatypes => can't apply Operations between them.\n",
        "  2. Tensors not right shape.           [ we will learn later how ]\n",
        "  3. Tensors not in the right device.   [ to manipulat that isues ]\n",
        "\"\"\"\n",
        "\n",
        "# the default tensor datatype is \"torch.float32\":\n",
        "tensor = torch.tensor([])\n",
        "\n",
        "print(f\"Tensor datatype: {tensor.dtype}\") # it is by default is \"torch.float32\""
      ],
      "metadata": {
        "id": "YKK2-MeAWyMj",
        "outputId": "107c2edc-c2da-436f-85cc-dfa83cea6631",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor datatype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# all the other ways to create a tenosrs the default datatype is \"torch.float32\"\n",
        "\"\"\"\n",
        "random_tensor = torch.rand(size = (2, 3))\n",
        "zeros_tensor = torch.zeros(size = (2, 3))\n",
        "ones_tensor = torch.ones(size = (2, 3))\n",
        "\n",
        "# also the tensor_like methods (rand_like, zeros_like, ones_like):\n",
        "rand_like_tenosr = torch.rand_like(zeros_tensor)\n",
        "\n",
        "print(f\"ranodm Tensor datatype: {random_tensor.dtype}\")\n",
        "print(f\"zeros Tensor datatype: {zeros_tensor.dtype}\")\n",
        "print(f\"ones Tensor datatype: {ones_tensor.dtype}\")\n",
        "print(f\"like Tensor datatype: {rand_like_tenosr.dtype}\")"
      ],
      "metadata": {
        "id": "N7oVzFzvWyPG",
        "outputId": "2acfeea7-0cde-40f7-83e9-47f3a5cb64d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ranodm Tensor datatype: torch.float32\n",
            "zeros Tensor datatype: torch.float32\n",
            "ones Tensor datatype: torch.float32\n",
            "like Tensor datatype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# the default DataType of the tensor is:\n",
        "  - for integers inputs => torch.int64\n",
        "  - for float inputs => torch.float32\n",
        "\"\"\"\n",
        "\n",
        "tensor1 = torch.tensor([1, 2, 3])\n",
        "tensor2 = torch.tensor([1., 2., 3.])\n",
        "\n",
        "print(f\"tensor1 Datatype: {tensor1.dtype}\")\n",
        "print(f\"tensor2 Datatype: {tensor2.dtype}\")"
      ],
      "metadata": {
        "id": "kiPESnydWySe",
        "outputId": "ccb1ed2d-bbd5-4bdf-f23c-ebc5d636852d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor1 Datatype: torch.int64\n",
            "tensor2 Datatype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# to change the Datatype we use \".type(Type)\" or \".to(Type)\":\n",
        "\"\"\"\n",
        "tensor1 = tensor1.type(torch.int8)             #.to(torch.int8)\n",
        "tensor2 = tensor2.type(torch.float16)          #.to(torch.float16)\n",
        "\n",
        "# the datatypes changed (int64 => int8 float32 => float16):\n",
        "print(f\"tensor1 Datatype: {tensor1.dtype}\")\n",
        "print(f\"tensor2 Datatype: {tensor2.dtype}\")"
      ],
      "metadata": {
        "id": "8o5gnwnDWyZY",
        "outputId": "71a23a99-d64d-4804-8cfd-753723103303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor1 Datatype: torch.int8\n",
            "tensor2 Datatype: torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# the bits in datatypes is important to (save ununsed memory + apply faster operations).\n",
        "# for float: 3.123456789\n",
        "  - float 16 => 16 bits => stores (3 - 4) decimal after the point ex: (3.123)\n",
        "  - float 32 => 32 bits => stores (6 - 7) decimal ex: (3.1234567)\n",
        "  - float 64 => 64 bits => stores (10) decimals ex: (3.123456789)\n",
        "# for int:\n",
        "  - int 8 => 8 bits => number between (-128 _ -127)\n",
        "  - int 16 => 16 bits => number between (-32k _ 32k)\n",
        "  - int 32 => 32 bits => number between (-2100M  _ 2100M)\n",
        "  - int 64 => 64 bits => number between (very large number)\n",
        "  # the different between signed and unsigned is (signed save the sing (+ / -) and unsigned don't save it (all +))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "h5W5Hn1tWyby",
        "outputId": "d25a90f3-f57f-4f7c-d7f0-37432f280ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# the bits in datatypes is important to (save ununsed memory + apply faster operations).\\n# for float: 3.123456789\\n  - float 16 => 16 bits => stores (3 - 4) decimal after the point ex: (3.123)\\n  - float 32 => 32 bits => stores (6 - 7) decimal ex: (3.1234567)\\n  - float 64 => 64 bits => stores (10) decimals ex: (3.123456789)\\n# for int:\\n  - int 8 => 8 bits => number between (-128 _ -127)\\n  - int 16 => 16 bits => number between (-32k _ 32k)\\n  - int 32 => 32 bits => number between (-2100M  _ 2100M)\\n  - int 64 => 64 bits => number between (very large number)\\n  # the different between signed and unsigned is (signed save the sing (+ / -) and unsigned don't save it (all +))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### Operations between different types.\n",
        "  - between 1. (different floats) 2. (different ints) ex: torch.float16 * torch.float32 (it converted to the bigger type) torch.float32\n",
        "  - between integer tensor and float tensor => the result is torch.float tensor.\n",
        "  - between numeric number and Boolean => ERROR!!!\n",
        "\"\"\"\n",
        "# Examples:\n",
        "\n",
        "# different Datatypes with the same (Datatype Family):\n",
        "float_32_tensor = torch.tensor([1., 2., 3.])\n",
        "float_16_tensor = torch.tensor([1., 2., 3.], dtype = torch.float16)\n",
        "\n",
        "print(\"# different Datatypes with the same (Datatype Family):\\n\")\n",
        "print(f\"float32 * float16:\\n{float_32_tensor * float_16_tensor}\")\n",
        "print(f\"Type: {(float_32_tensor * float_16_tensor).dtype}\")\n",
        "\n",
        "# integer * float:\n",
        "int_tensor = torch.tensor([1., 2., 3.], dtype= torch.int8)\n",
        "float_tensor = torch.tensor([1., 2., 3.], dtype = torch.float16)\n",
        "print(\"\\n# integer * float:\\n\")\n",
        "print(f\"integer * float:\\n{int_tensor * float_tensor}\")\n",
        "print(f\"Type: {(int_tensor * float_tensor).dtype}\")"
      ],
      "metadata": {
        "id": "ud-PBzF4WyfR",
        "outputId": "a9521c19-1161-49f3-da8e-17df65c2bc03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# different Datatypes with the same (Datatype Family):\n",
            "\n",
            "float32 * float16:\n",
            "tensor([1., 4., 9.])\n",
            "Type: torch.float32\n",
            "\n",
            "# integer * float:\n",
            "\n",
            "integer * float:\n",
            "tensor([1., 4., 9.], dtype=torch.float16)\n",
            "Type: torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# change the data type of the tensor by \"dtype\" parameter in the torch.tensor\"\n",
        "\"\"\"\n",
        "tensor = torch.tensor([2., 3.], dtype = torch.float16) # also to int8, 16, 32...\n",
        "tensor, tensor.dtype"
      ],
      "metadata": {
        "id": "3GNKQ86BsBK_",
        "outputId": "c2638539-28f8-4b6d-b1c6-0486fe12bf1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 3.], dtype=torch.float16), torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change type of tensor in torch.rand (from torch.float32 => torch.float16)\n",
        "tensor = torch.rand(2, 3, dtype = torch.float16)\n",
        "tensor, tensor.dtype"
      ],
      "metadata": {
        "id": "vITMTgPSscjd",
        "outputId": "60645498-22da-4053-daf2-a8f501f8d72c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1431, 0.1504, 0.0464],\n",
              "         [0.0483, 0.3589, 0.0010]], dtype=torch.float16),\n",
              " torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors (Mathmatical Operation)**"
      ],
      "metadata": {
        "id": "8do1304hRgMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# we can apply a Mathmatical Operations on Tensors:\n",
        "  - addition, subtraction\n",
        "  - multiplication (element wise multiplication), devision\n",
        "  - Matrix multiplication (Dot Product)\n",
        "\"\"\"\n",
        "MATRIX = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "\n",
        "# MATRIX +, -, *, / Scalar => apply the value element wise\n",
        "MATRIX - 1"
      ],
      "metadata": {
        "id": "GLITHSfRRtNH",
        "outputId": "0b45d853-c324-43b4-d3f8-d4db979951ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# MATRIX (+, -, *, /) MATRIX (Normal operations) => element wise ex: element in M1 - element in M2\n",
        "# they should be THE SAME size.\n",
        "\"\"\"\n",
        "\n",
        "MATRIX1 = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "\n",
        "MATRIX2 = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "\n",
        "print(f\"Matries Sum: \\n{MATRIX1 + MATRIX2}\\n\")\n",
        "print(f\"\\nMatries Multiply: \\n{MATRIX1 * MATRIX2}\\n\")"
      ],
      "metadata": {
        "id": "3Md2qqnWRvnv",
        "outputId": "794d3930-29b8-4319-9f09-694f103cfe86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matries Sum: \n",
            "tensor([[ 2,  4,  6],\n",
            "        [ 8, 10, 12]])\n",
            "\n",
            "\n",
            "Matries Multiply: \n",
            "tensor([[ 1,  4,  9],\n",
            "        [16, 25, 36]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# the most operation in PyTorch is the \"Dot Product\" as we learn it have 2 Rules:\n",
        "  1. The inner values in shape must be the same thing:\n",
        "     (2 * 3) . (2 * 3) => Error!! (3 not eqal 2)\n",
        "     (4 * 2) . (2 * 8) => Yes (2 == 2)\n",
        "  2. The result is the Outer values in shape (a * b) . (b * c) => result (a * c)\n",
        "     (4 * 2) . (2 * 2) => result (4 * 2)\n",
        "\n",
        "\"\"\"\n",
        "# create Matries:\n",
        "M1 = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "\n",
        "M2 = torch.tensor([[1, 2],\n",
        "                   [3, 4],\n",
        "                   [5, 6]])\n",
        "\n",
        "print(f\"M1:\\n{M1}\\n{M1.shape}\\n\\nM2:\\n{M2}\\n{M2.shape}\")"
      ],
      "metadata": {
        "id": "pfe_jBMwZwq1",
        "outputId": "1ea08562-1684-4060-b452-d44e10e81584",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M1:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 3])\n",
            "\n",
            "M2:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# because the inner values are the same 3 ==3 so M1 torch.Size([2, 3]) M2 torch.Size([3, 2]), so we can apply Dot Product and the result are Outers[2 * 2].\n",
        "# to apply the \"Dot Product\" in Pytorch we can use:\n",
        "  - \"@\" symbol => M1 @ M2\n",
        "  - .matmul(Matrix multiplication) method => torch.matmul(M1, M2)\n",
        "  # there is a short-cut method for the matmul() which is \".mm()\".\n",
        "\"\"\"\n",
        "# Matrix detales:\n",
        "print(f\"M1:\\n{M1}\\n{M1.shape}\")\n",
        "print(f\"\\nM2:\\n{M2}\\n{M2.shape}\\n\")\n",
        "\n",
        "# Matrix Multiplication:\n",
        "torch.matmul(M1, M2)"
      ],
      "metadata": {
        "id": "DmxJRjIgeGZW",
        "outputId": "234045b9-cfb5-4afc-b961-3c694ba316f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M1:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 3])\n",
            "\n",
            "M2:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "torch.Size([3, 2])\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[22, 28],\n",
              "        [49, 64]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# the most common error we will see is when we try to apply \"Dot Product\" in Uncorrect shape.\n",
        "# the error is \"mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)\"\n",
        "\"\"\"\n",
        "# Error Matrix shape:\n",
        "M3 = torch.tensor([[7, 8, 9],\n",
        "                  [10, 11, 12]])\n",
        "print(\"could we apply Dot Product for:\")\n",
        "print(f\"M1:\\n{M1}\\n{M1.shape}\")\n",
        "print(f\"\\nM3:\\n{M3}\\n{M3.shape}\\n\")"
      ],
      "metadata": {
        "id": "BzNfY5qbgO5N",
        "outputId": "2b638231-65e0-4954-fbba-5281d6cfa3a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "could we apply Dot Product for:\n",
            "M1:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 3])\n",
            "\n",
            "M3:\n",
            "tensor([[ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "torch.Size([2, 3])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape error in multiplication:\n",
        "torch.matmul(M1, M3)"
      ],
      "metadata": {
        "id": "NPCVvDC2hhCV",
        "outputId": "1e0871f6-3e7b-4d27-dbcc-9e2886634a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2064666652.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Shape error in multiplication:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix Transpos**"
      ],
      "metadata": {
        "id": "r2xAKU6rjfvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix to use:\n",
        "print(f\"M1:\\n{M1}\\n{M1.shape}\")\n",
        "print(f\"\\nM2:\\n{M2}\\n{M2.shape}\\n\")\n",
        "print(f\"\\nM3:\\n{M3}\\n{M3.shape}\\n\")\n"
      ],
      "metadata": {
        "id": "DnNUnjqTjaNV",
        "outputId": "c7689905-e701-48af-880a-f463ee22981a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M1:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 3])\n",
            "\n",
            "M2:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "torch.Size([3, 2])\n",
            "\n",
            "\n",
            "M3:\n",
            "tensor([[ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "torch.Size([2, 3])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Transpose we use when we need to rotat the Matrix to apply the \"Dot Product\".\n",
        "# the Transpose switch the shape (2 * 3) => (3 * 2).\n",
        "# for each column rotate it iverce of the clock (ðŸ”„) to be a row.\n",
        "# to Transpose a Matrix we use \".T\" on the matrix => matrix.T\n",
        "\"\"\"\n",
        "print(f\"M3:\\n{M3}\\n{M3.shape}\\n\")\n",
        "print(f\"\\nM3:\\n{M3.T}\\n{M3.T.shape}\\n\")"
      ],
      "metadata": {
        "id": "xU2oaKHfjaQs",
        "outputId": "f550e0e3-3a58-4bdf-b5a0-2e90ebf958d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M3:\n",
            "tensor([[ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "torch.Size([2, 3])\n",
            "\n",
            "\n",
            "M3:\n",
            "tensor([[ 7, 10],\n",
            "        [ 8, 11],\n",
            "        [ 9, 12]])\n",
            "torch.Size([3, 2])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can Multiply the M1 and transpose of M3:\n"
      ],
      "metadata": {
        "id": "zOPlulEyjaXC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nM1:\\n{M1}\\n{M1.shape}\\n\")\n",
        "print(f\"\\nM3:\\n{M3.T}\\n{M3.T.shape}\\n\")\n",
        "\n",
        "print(f\"M1 . M3.T:\\n{torch.matmul(M1, M3.T)}\\n{torch.matmul(M1, M3.T).shape}\")"
      ],
      "metadata": {
        "id": "bObdm7_PjaZw",
        "outputId": "e2a72e51-2414-4134-ea22-d77ec50e4f21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "M1:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 3])\n",
            "\n",
            "\n",
            "M3:\n",
            "tensor([[ 7, 10],\n",
            "        [ 8, 11],\n",
            "        [ 9, 12]])\n",
            "torch.Size([3, 2])\n",
            "\n",
            "M1 . M3.T:\n",
            "tensor([[ 50,  68],\n",
            "        [122, 167]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor aggregation (min, max, sum, mean) + (minarg, maxarg)**"
      ],
      "metadata": {
        "id": "tVVOm-mPAN6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# to find the aggregation we can use one of these syntacs:\n",
        "  - torch.agg(Tensor) => torch.min(M1)\n",
        "  - Tensor.agg() => M1.min()\n",
        "\"\"\"\n",
        "M = M1.type(torch.float32)\n",
        "# we will use this tensor\n",
        "print(f\"\\nM1:\\n{M}\")"
      ],
      "metadata": {
        "id": "HXLwfnzyAPZ_",
        "outputId": "902248ba-8df5-40e4-bbca-a81be2536be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "M1:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# min:\n",
        "print(f\"min:\\n{torch.min(M), M.min()}\\n\")\n",
        "\n",
        "# max:\n",
        "print(f\"max:\\n{torch.max(M), M.max()}\")"
      ],
      "metadata": {
        "id": "6letL-UWAPcM",
        "outputId": "64a9d32f-00f6-4ba0-f711-51d80932e1fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min:\n",
            "(tensor(1.), tensor(1.))\n",
            "\n",
            "max:\n",
            "(tensor(6.), tensor(6.))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to find the \"sum\" use:\n",
        "print(f\"max:\\n{torch.sum(M), M.sum()}\")"
      ],
      "metadata": {
        "id": "eLYT2UlKAPet",
        "outputId": "f01abe21-453a-4e74-c874-7c9076afacc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max:\n",
            "(tensor(21.), tensor(21.))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# the mean function only take input of (float or complex) in doesn't take the integer or long.\n",
        "\"\"\"\n",
        "# M.type(torch.int32).mean() # Error!! long datatype\n",
        "\n",
        "# only with float or complex:\n",
        "M.dtype, torch.mean(M), M.mean()"
      ],
      "metadata": {
        "id": "j7ZFK1XqAPiP",
        "outputId": "ece3e1c2-6d2f-445a-8509-90cd593a3fac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, tensor(3.5000), tensor(3.5000))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# some time we don't need to find the (min) or (max) we need to find the index of them, so we use the \"argmin\" and \"argmax\".\n",
        "# we need the \"argmin\" and \"argmax\" in the Softmax function.\n",
        "\"\"\"\n",
        "print(M)\n",
        "\n",
        "# argmin:\n",
        "torch.argmin(M), M.argmin() # index (0) the minimum number [1]"
      ],
      "metadata": {
        "id": "k3iTSh74APr8",
        "outputId": "d3a87899-8ffa-4294-c0a3-032ef72e9878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#argmax:\n",
        "torch.argmax(M), M.argmax() # index (5) the maximum number [6]"
      ],
      "metadata": {
        "id": "NVbZKTRpAPvb",
        "outputId": "1a158c36-bb53-401d-c717-dd75a5694f2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5), tensor(5))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reshaping, stacking, squeezing, and unsqueezing Tensors**"
      ],
      "metadata": {
        "id": "Pzy7FETBElZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# these are importent topics in the Tesors manipulation.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VHRAcs08EmXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwRdb6dNEmaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sm-a-xzWEmct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W3-3JLMvEmfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x4Ea9xoDEmh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dhIvGO32EmkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQH66w6gEmmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vs4NmKyMEmp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gycPSz4C-mmr"
      },
      "source": [
        "**Multiplying tensors**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL-qHw8X-mmr"
      },
      "outputs": [],
      "source": [
        "# This computes the element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INpo6bV8-mmr"
      },
      "source": [
        "This computes the matrix multiplication between two tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THi6roXZ-mmr"
      },
      "outputs": [],
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f40M8O8Z-mmr"
      },
      "source": [
        "**In-place operations** Operations that have a `_` suffix are in-place.\n",
        "For example: `x.copy_(y)`, `x.t_()`, will change `x`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojWsGWwR-mmr"
      },
      "outputs": [],
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMaFpXBu-mmr"
      },
      "source": [
        "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
        "\n",
        "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
        "\n",
        "<p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate lossof history. Hence, their use is discouraged.</p>\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_ubjCRx-mmr"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr-YF3o5-mmr"
      },
      "source": [
        "Bridge with NumPy {#bridge-to-np-label}\n",
        "=================\n",
        "\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory\n",
        "locations, and changing one will change the other.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtBZF7sm-mmr"
      },
      "source": [
        "Tensor to NumPy array\n",
        "=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAIVr3MX-mmr"
      },
      "outputs": [],
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF7qi-Dt-mmr"
      },
      "source": [
        "A change in the tensor reflects in the NumPy array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBv0oZ-f-mmr"
      },
      "outputs": [],
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSgApUmn-mms"
      },
      "source": [
        "NumPy array to Tensor\n",
        "=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLCQNwmK-mms"
      },
      "outputs": [],
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKkZ2iNk-mms"
      },
      "source": [
        "Changes in the NumPy array reflects in the tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG6tY1lB-mms"
      },
      "outputs": [],
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}